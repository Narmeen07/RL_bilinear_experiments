{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can import modules from this directory\n",
    "import torch\n",
    "import os\n",
    "from src.plotter import EigenvectorPlotter\n",
    "from src.heist import load_model\n",
    "import imageio\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.helpers import action_space, evaluate_model\n",
    "from collections import Counter\n",
    "import random\n",
    "from procgen import ProcgenEnv\n",
    "from src.vec_env import VecExtractDictObs, VecMonitor, VecNormalize\n",
    "from src.bilinear_impala_simplified import BimpalaCNN, TopKBimpalaCNN\n",
    "import matplotlib.pyplot as plt\n",
    "from src.heist import create_venv as create_venv_simple\n",
    "import einops\n",
    "from src.utils import *\n",
    "from src.helpers import ModelActivations, get_model_layer_names\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, set_start_method\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import pickle\n",
    "import src.ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/bilinear_models/bimpala_maze_simplified.pt\n",
      "BimpalaCNN(\n",
      "  (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (conv_seqs): ModuleList(\n",
      "    (0-2): 3 x ConvSequence(\n",
      "      (max_pool2d): MaxPool2d(kernel_size=7, stride=2, padding=3, dilation=1, ceil_mode=False)\n",
      "      (res_block0): ResidualBlock(\n",
      "        (conv0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      )\n",
      "      (res_block1): ResidualBlock(\n",
      "        (conv0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hidden_fc1): Linear(in_features=2048, out_features=256, bias=False)\n",
      "  (hidden_fc2): Linear(in_features=2048, out_features=256, bias=False)\n",
      "  (logits_fc): Linear(in_features=256, out_features=15, bias=True)\n",
      "  (value_fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "conv.weight\n",
      "conv.bias\n",
      "conv_seqs.0.res_block0.conv0.weight\n",
      "conv_seqs.0.res_block0.conv1.weight\n",
      "conv_seqs.0.res_block1.conv0.weight\n",
      "conv_seqs.0.res_block1.conv1.weight\n",
      "conv_seqs.1.res_block0.conv0.weight\n",
      "conv_seqs.1.res_block0.conv1.weight\n",
      "conv_seqs.1.res_block1.conv0.weight\n",
      "conv_seqs.1.res_block1.conv1.weight\n",
      "conv_seqs.2.res_block0.conv0.weight\n",
      "conv_seqs.2.res_block0.conv1.weight\n",
      "conv_seqs.2.res_block1.conv0.weight\n",
      "conv_seqs.2.res_block1.conv1.weight\n",
      "hidden_fc1.weight\n",
      "hidden_fc2.weight\n",
      "logits_fc.weight\n",
      "logits_fc.bias\n",
      "value_fc.weight\n",
      "value_fc.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/src/heist.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = \"/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/bilinear_models/bimpala_maze_simplified.pt\"\n",
    "model =load_model(model_path,7)\n",
    "print(model)\n",
    "for k in model.state_dict():\n",
    "    print(k)\n",
    "state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.ppo import Config, PPO, create_venv,create_gif\n",
    "env_config = Config()\n",
    "device = torch.device(f'cuda:{env_config.gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "agent = PPO(model.to(device),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ppo import rollout_episode_obs\n",
    "def create_dataset_one_episode(model, device, num_levels= 0, progress= 20, env_name = \"maze\"):\n",
    "    \n",
    "    env = create_venv_simple(num_envs=1, start_level=random.randint(0, 1000000000), num_levels=num_levels, env_name=env_name)\n",
    "    agent = PPO(model, device)\n",
    "    envs = rollout_episode_obs(agent, env, progress= progress)\n",
    "    return envs\n",
    "def create_dataset_multiple_episodes(model, device, num_levels= 0):   \n",
    "    env = create_venv_simple(num_envs=1, start_level=random.randint(0, 1000000000), num_levels=num_levels, env_name=\"maze\")\n",
    "    return [env.reset()]\n",
    "\n",
    "def get_activations(modelactivations: ModelActivations,observation, layers, device):\n",
    "    observation = torch.tensor(observation, device=device, dtype=torch.float32)\n",
    "    _, activations = modelactivations.run_with_cache(observation, layers)\n",
    "    return activations\n",
    "\n",
    "def get_activations_for_dataset(modelactivations, dataset, layers, device):\n",
    "    dataset_with_activations = []\n",
    "    # Use tqdm to show a progress bar over the dataset iteration\n",
    "    for observation in tqdm(dataset, desc=\"Computing activations\"):\n",
    "        # Convert the observation to a tensor\n",
    "        observation_tensor = torch.tensor(observation, device=device, dtype=torch.float32)\n",
    "        # Compute activations\n",
    "        _, activation = modelactivations.run_with_cache(observation_tensor, layers)\n",
    "        # Append both observation and its activations to the new dataset list\n",
    "        dataset_with_activations.append((observation_tensor, activation[layers[0].replace('.', '_')][0]))\n",
    "    return dataset_with_activations\n",
    "\n",
    "def find_top_observations_by_eigenvector(dataset,eigenvalues, eigenvectors, topk=15, topk_images = 50):\n",
    "\n",
    "\n",
    "    # Initialize tensors to store the top-k eigenvalues and eigenvectors for each class\n",
    "    sorted_indices = torch.argsort(torch.abs(eigenvalues), descending=True)\n",
    "    topk_indices = sorted_indices[:topk]\n",
    "    top_k_eigenvalues = eigenvalues[topk_indices]\n",
    "    top_k_eigenvectors = eigenvectors[:, topk_indices]\n",
    "    \n",
    "    results = {i: {'top_observations': [], 'max_score': float('-inf')} for i in range(top_k_eigenvectors.size(-1))}\n",
    "\n",
    "    # Wrap the outer loop with tqdm for a progress bar\n",
    "    for observation, activation in tqdm(dataset, desc=\"Processing Observations\"):\n",
    "        \n",
    "        activation_flat = activation.reshape(1, -1).to(device)\n",
    "        #print(\"shape of activation and eigenvectors\", activation_flat.squeeze(0).shape,top_k_eigenvectors.shape, top_k_eigenvalues.shape )\n",
    "        # Compute dot product for each eigenvector\n",
    "        dot_products = torch.einsum('a, a t -> t', activation_flat.squeeze(0), top_k_eigenvectors.to(activation_flat.device))\n",
    "        sims = top_k_eigenvalues.to(activation_flat.device) * dot_products**2\n",
    "        #print(\"shape of sims\", sims.shape)\n",
    "   \n",
    "        # Update results for each eigenvector\n",
    "        for i, value in enumerate(sims):\n",
    "            score= torch.abs(value)\n",
    "            if score > results[i]['max_score']:\n",
    "                results[i]['max_score'] = value.item()\n",
    "            results[i]['top_observations'].append((observation, value.item()))\n",
    "\n",
    "    # Sort and limit to top k observations for each eigenvector after all are processed\n",
    "    for i in results:\n",
    "        results[i]['top_observations'] = list(results[i]['top_observations'])\n",
    "        results[i]['top_observations'].sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        results[i]['top_observations'] = results[i]['top_observations'][:topk_images]\n",
    "\n",
    "    return results, top_k_eigenvalues \n",
    "def generate_dataset(directory, progress=20, env_name = \"maze\"):\n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "    for j in range(5):\n",
    "        dataset = []\n",
    "        # Wrap the inner loop with tqdm for progress tracking\n",
    "        for i in tqdm(range(2000), desc=f'Generating Dataset for Batch {j}'):\n",
    "            dataset.extend(create_dataset_one_episode(model, device, progress=progress, env_name = env_name))\n",
    "        output_path = os.path.join(directory, f'{env_name}_dataset_progress_{progress}_batch{j}.pickle')\n",
    "        # Save the dataset to a pickle file\n",
    "        with open(output_path, 'wb') as file:\n",
    "            pickle.dump(list(dataset), file)\n",
    "def load_and_combine_datasets(num_files, dataset_folder=\"\", progress= 20, env_name = \"maze\"):\n",
    "    # List to hold all observations from all datasets\n",
    "    all_observations = []\n",
    "    \n",
    "    # Generate file names based on known naming pattern\n",
    "    dataset_files = [f'datasets/{env_name}_dataset_progress_{progress}_batch{i}.pickle' for i in range(num_files)]\n",
    "\n",
    "    # Loop through each file, load it, and extend the master list\n",
    "    for dataset_file in dataset_files:\n",
    "        file_path = os.path.join(dataset_folder, dataset_file)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            all_observations.extend(data)\n",
    "    \n",
    "    return all_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv', 'conv_seqs', 'conv_seqs.0', 'conv_seqs.0.max_pool2d', 'conv_seqs.0.res_block0', 'conv_seqs.0.res_block0.conv0', 'conv_seqs.0.res_block0.conv1', 'conv_seqs.0.res_block1', 'conv_seqs.0.res_block1.conv0', 'conv_seqs.0.res_block1.conv1', 'conv_seqs.1', 'conv_seqs.1.max_pool2d', 'conv_seqs.1.res_block0', 'conv_seqs.1.res_block0.conv0', 'conv_seqs.1.res_block0.conv1', 'conv_seqs.1.res_block1', 'conv_seqs.1.res_block1.conv0', 'conv_seqs.1.res_block1.conv1', 'conv_seqs.2', 'conv_seqs.2.max_pool2d', 'conv_seqs.2.res_block0', 'conv_seqs.2.res_block0.conv0', 'conv_seqs.2.res_block0.conv1', 'conv_seqs.2.res_block1', 'conv_seqs.2.res_block1.conv0', 'conv_seqs.2.res_block1.conv1', 'hidden_fc1', 'hidden_fc2', 'logits_fc', 'value_fc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing activations: 100%|██████████| 24509/24509 [00:39<00:00, 626.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#generate_dataset(directory=\"datasets\", env_name= 'heist')\n",
    "dataset = load_and_combine_datasets(5)\n",
    "modelactivations = ModelActivations(model)\n",
    "print(get_model_layer_names(model))\n",
    "enhanced_dataset = get_activations_for_dataset(modelactivations, dataset,['conv_seqs.2.res_block1.conv1'],device)\n",
    "\n",
    "print(len(enhanced_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.heist import create_venv as create_env\n",
    "def compute_B_sym(W, V, proj_out= None, type = \"mlp\"):\n",
    "    if type == \"mlp\":\n",
    "        B = einops.einsum(W,V, \"out in1, out in2 -> out in1 in2\").to(W.device)\n",
    "        B = 0.5 * B + 0.5 * B.transpose(-2,-1)\n",
    "        B = einops.rearrange(B, \"out in1 in2 -> out (in1 in2)\")\n",
    "        B = einops.rearrange(B, \"out (in1 in2) -> out in1 in2\", in1 = 2048)\n",
    "        B_proj = einops.einsum(proj_out, B, \"class h2, h2 in1 in2-> class in1 in2\")\n",
    "        return  0.5 * B_proj + 0.5 * B_proj.transpose(-2,-1)\n",
    "\n",
    "    else:\n",
    "        c_out, c_in, k, _ = W.shape\n",
    "        B = torch.zeros(c_out, c_in*k*k, c_in*k*k, device=W.device, dtype=W.dtype)\n",
    "        \n",
    "        for l in range(c_out):\n",
    "            W_outl = W[l]  # c_in by k by k\n",
    "            V_outl = V[l]  # c_in by k by k\n",
    "            for i in range(c_in):\n",
    "                for j in range(c_in):\n",
    "                    W_i = W_outl[i]  # k x k\n",
    "                    V_j = V_outl[j]  # k x k\n",
    "                    W_i_f = W_i.reshape(-1)  # k*k\n",
    "                    V_j_f = V_j.reshape(-1)  # k*k\n",
    "                    block = torch.outer(W_i_f, V_j_f)  # k*k x k*k\n",
    "                    B[l, i*k*k:(i+1)*k*k, j*k*k:(j+1)*k*k] = block\n",
    "        #Symmetrysing B            \n",
    "        B_sym = torch.zeros_like(B)\n",
    "        for o in range(c_out):\n",
    "            B_sym[o] = 0.5 * (B[o] + B[o].T) \n",
    "        return B_sym\n",
    "\n",
    "#W, V, proj_out =model.hidden_fc1.weight, model.hidden_fc2.weight, model.logits_fc.weight\n",
    "W = state_dict['conv_seqs.2.res_block1.conv0.weight']\n",
    "V = state_dict['conv_seqs.2.res_block1.conv1.weight']\n",
    "B_sym = compute_B_sym(W=W, V=V, type=\"conv\")\n",
    "\n",
    "def initialize_models(obs_space, num_outputs, kernel_size,topk=2048, B_sym= B_sym):\n",
    "    original_model = BimpalaCNN(obs_space, num_outputs, kernel_size)\n",
    "    model_path = \"/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/bilinear_models/bimpala_maze_simplified.pt\"\n",
    "    original_model = load_model(model_path,7)\n",
    "    # Create the modified model\n",
    "    modified_model = TopKBimpalaCNN(obs_space, num_outputs, kernel_size=kernel_size, topk= topk,B=B_sym, replacement_layers=[\"conv_seq_2\"])\n",
    "    \n",
    "    modified_model.transfer_params_from(original_model)\n",
    "    \n",
    "    return original_model, modified_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from src.ppo import rollout_episode,create_gif,PPO\n",
    "def evaluate_model_multi_env(model, create_env, num_episodes=100,gif= None, device = torch.device(f'cuda:3' if torch.cuda.is_available() else 'cpu')):\n",
    "    \"\"\"\n",
    "    Evaluate a trained PPO model over multiple episodes across multiple environments.\n",
    "    \n",
    "    Args:\n",
    "    - agent: The trained PPO agent\n",
    "    - env_creator: A function that creates and returns an environment\n",
    "    - env_configs: A list of dictionaries, each containing configuration for an environment\n",
    "    - num_episodes: Number of episodes to run for evaluation per environment\n",
    "    - render_every: If not None, render every nth episode\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing evaluation metrics for each environment and overall\n",
    "    \"\"\"\n",
    "\n",
    "    overall_results = defaultdict(list)\n",
    "\n",
    "    agent = PPO(model=model, device=device)\n",
    "    \n",
    "\n",
    "    total_rewards = [None] * num_episodes\n",
    "    success_count = 0\n",
    "    success_info = [None] * num_episodes\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        env = create_env()\n",
    "        env.reset()\n",
    "        frames, reward, info = rollout_episode(agent,env, return_info=True)\n",
    "        total_rewards[episode] = reward\n",
    "        if reward >0:\n",
    "            success_count += 1\n",
    "        success_info[episode] = info['r']\n",
    "\n",
    "        if gif:\n",
    "            create_gif(frames, f\"{gif}_{episode}.gif\")\n",
    "          \n",
    "    percentage_success = success_count/num_episodes\n",
    "    percentage_info_success = sum(success_info)/num_episodes\n",
    "    env_results = {\n",
    "        \"mean_reward\": np.mean(success_info),\n",
    "        \"std_reward\": np.std(success_info),\n",
    "        \"min_reward\": np.min(total_rewards),\n",
    "        \"max_reward\": np.max(total_rewards),\n",
    "        \"percentage_success\": percentage_success,\n",
    "        #\"percentage_info_success\": percentage_info_success\n",
    "\n",
    "    }\n",
    "\n",
    "    return env_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topk_results(results_list):\n",
    "    topk_values = [res['topk'] if res['topk'] != 0 else 0.1 for res in results_list]\n",
    "    original_topk_labels = [res['topk'] for res in results_list]\n",
    "\n",
    "    mean_rewards = [res['mean_reward'] for res in results_list]\n",
    "    std_rewards = [res['std_reward'] for res in results_list]\n",
    "    success_rates = [res['percentage_success'] for res in results_list]\n",
    "\n",
    "    # Create a new figure and axis\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plot mean_reward with error bars on the first y-axis\n",
    "    ax1.set_xlabel('Top-k Model')\n",
    "    ax1.set_ylabel('Mean Reward', color='tab:blue')\n",
    "    ax1.errorbar(topk_values, mean_rewards, yerr=std_rewards, fmt='o-', color='tab:blue', \n",
    "                 label='Mean Reward', capsize=5, capthick=2, ecolor='lightblue')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax1.set_xscale('log')\n",
    "\n",
    "    # Create a second y-axis for success_rate\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Success Rate (%) out of 100 trials', color='tab:green')\n",
    "    ax2.plot(topk_values, success_rates, color='tab:green', marker='x', label='Success Rate')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "\n",
    "    # Custom tick labels for top-k, to display '0' instead of 0.1\n",
    "    ax1.set_xticks(topk_values)\n",
    "    ax1.set_xticklabels([str(x) if x != 0.1 else '0' for x in original_topk_labels])\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('Mean Reward (with Std Dev) and Success Rate Over Different Top-k Values')\n",
    "\n",
    "    # Show legends\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    # Adjust layout to prevent clipping of tick-labels\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = state_dict['conv_seqs.2.res_block1.conv0.weight']\n",
    "V = state_dict['conv_seqs.2.res_block1.conv1.weight']\n",
    "B_sym = compute_B_sym(W=W, V=V, type=\"conv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/bilinear_models/bimpala_maze_simplified.pt\n",
      "Parameters transferred and modified successfully\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'top_k_eigenfilters' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m env \u001b[38;5;241m=\u001b[39m create_env()\n\u001b[1;32m      5\u001b[0m usual_model, modified_model \u001b[38;5;241m=\u001b[39m initialize_models(env\u001b[38;5;241m.\u001b[39mobservation_space, env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m, topk\u001b[38;5;241m=\u001b[39mtopk,B_sym\u001b[38;5;241m=\u001b[39m B_sym)\n\u001b[0;32m----> 6\u001b[0m results[i] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_multi_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodified_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_env\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcreate_venv_simple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgif\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m results[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopk\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m topk\n\u001b[1;32m      8\u001b[0m topk \u001b[38;5;241m=\u001b[39m topk\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \n",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m, in \u001b[0;36mevaluate_model_multi_env\u001b[0;34m(model, create_env, num_episodes, gif, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m env \u001b[38;5;241m=\u001b[39m create_env()\n\u001b[1;32m     29\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 30\u001b[0m frames, reward, info \u001b[38;5;241m=\u001b[39m \u001b[43mrollout_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m total_rewards[episode] \u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/src/ppo.py:111\u001b[0m, in \u001b[0;36mrollout_episode\u001b[0;34m(agent, env, return_info)\u001b[0m\n\u001b[1;32m    109\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m--> 111\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     obs, reward, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Render the current environment state as an RGB array\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/src/ppo.py:40\u001b[0m, in \u001b[0;36mPPO.batch_act\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Ensure the observations are on the correct device and in the correct dtype\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     observations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(observations, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 40\u001b[0m     dist, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dist\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/src/bilinear_impala_simplified.py:209\u001b[0m, in \u001b[0;36mTopKBimpalaCNN.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     x \u001b[38;5;241m=\u001b[39m conv_seq\u001b[38;5;241m.\u001b[39mmax_pool2d(x)\n\u001b[1;32m    208\u001b[0m     x \u001b[38;5;241m=\u001b[39m conv_seq\u001b[38;5;241m.\u001b[39mres_block0(x)\n\u001b[0;32m--> 209\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_eigenvectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k_conv_eigenvals\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k_eigenfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:    \n\u001b[1;32m    212\u001b[0m     x \u001b[38;5;241m=\u001b[39m conv_seq(x)\n",
      "File \u001b[0;32m/mnt/ssd-1/mechinterp/narmeen/bilinear_experiments_official/bilinear_experiments/src/bilinear_impala_simplified.py:176\u001b[0m, in \u001b[0;36mTopKBimpalaCNN.apply_eigenvectors\u001b[0;34m(self, x, top_k_eigenvalues, top_k_eigenvectors, type)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     top_k_eigenfilters \u001b[38;5;241m=\u001b[39m top_k_eigenvectors\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mtop_k_eigenfilters\u001b[49m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m7\u001b[39m,top_k_eigenvectors\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    177\u001b[0m     out_channels, c_in, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m7\u001b[39m\n\u001b[1;32m    178\u001b[0m     out_activations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(out_channels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopk, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'top_k_eigenfilters' referenced before assignment"
     ]
    }
   ],
   "source": [
    "topk = 1568\n",
    "results = [None] * 13\n",
    "for i in range(13):\n",
    "    env = create_env()\n",
    "    usual_model, modified_model = initialize_models(env.observation_space, env.action_space.n, kernel_size = 7, topk=topk,B_sym= B_sym)\n",
    "    results[i] = evaluate_model_multi_env(model = modified_model, create_env = create_venv_simple, num_episodes=1, gif=\"gif\")\n",
    "    results[i]['topk'] = topk\n",
    "    topk = topk//2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
