{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "GATED_CONV_LAYERS = [\n",
    "    \"conv_seqs.0.res_block0\",\n",
    "    \"conv_seqs.0.res_block1\",\n",
    "    \"conv_seqs.1.res_block0\",\n",
    "    \"conv_seqs.1.res_block1\",\n",
    "    \"conv_seqs.2.res_block0\",\n",
    "    \"conv_seqs.2.res_block1\"\n",
    "]\n",
    "\n",
    "import torch\n",
    "def layer_to_b_tensor(W=None, V=None, layer_label=None, state_dict=None, device='cpu'):\n",
    "    if W is not None and V is not None:\n",
    "        W = W.to(dtype=torch.float64, device=device)\n",
    "        V = V.to(dtype=torch.float64, device=device)\n",
    "        \n",
    "        c_out, c_in, k, _ = W.shape\n",
    "        B = torch.zeros(c_out, c_in*k*k, c_in*k*k, dtype=torch.float64, device=device)\n",
    "\n",
    "        for l in range(c_out):\n",
    "            W_outl = W[l]\n",
    "            V_outl = V[l]\n",
    "            for i in range(c_in):\n",
    "                for j in range(c_in):\n",
    "                    W_i = W_outl[i]\n",
    "                    V_j = V_outl[j]\n",
    "                    W_i_f = W_i.reshape(-1)\n",
    "                    V_j_f = V_j.reshape(-1)\n",
    "                    block = torch.outer(W_i_f, V_j_f)\n",
    "                    B[l, i*k*k:(i+1)*k*k, j*k*k:(j+1)*k*k] = block\n",
    "\n",
    "        B_sym = torch.zeros_like(B, dtype=torch.float64)\n",
    "        for o in range(c_out):\n",
    "            B_sym[o] = 0.5 * (B[o] + B[o].T)\n",
    "        return B_sym\n",
    "    \n",
    "    elif layer_label is not None and state_dict is not None:\n",
    "        if layer_label in GATED_CONV_LAYERS:\n",
    "            W = state_dict[layer_label + \".conv0.weight\"].to(dtype=torch.float64, device=device)\n",
    "            V = state_dict[layer_label + \".conv1.weight\"].to(dtype=torch.float64, device=device)\n",
    "            return layer_to_b_tensor(W=W, V=V, device=device)\n",
    "    else:\n",
    "        raise ValueError(\"Either provide W and V or layer_label and state_dict\")\n",
    "\n",
    "def b_tensor_decomp(b_tensor, out_vector, topk=None, specified_idxs=None, device='cpu'):\n",
    "    b_tensor = b_tensor.to(dtype=torch.float64, device=device)\n",
    "    out_vector = out_vector.to(dtype=torch.float64, device=device)\n",
    "    b_tensor = torch.einsum(\"oij, o-> ij\", b_tensor, out_vector)\n",
    "    eigvals, eigvecs = torch.linalg.eigh(b_tensor)\n",
    "\n",
    "    \n",
    "    if specified_idxs is not None:\n",
    "        specified_eigvals = eigvals[specified_idxs]\n",
    "        specified_eigvecs = eigvecs[:, specified_idxs]\n",
    "        return specified_eigvals, specified_eigvecs\n",
    "        \n",
    "    if topk is None:\n",
    "        topk = eigvecs.shape[1]\n",
    "        \n",
    "    sorted_indices = torch.argsort(torch.abs(eigvals), descending=True)\n",
    "    topk_indices = sorted_indices[:topk]\n",
    "    topk_eigvals = eigvals[topk_indices]\n",
    "    topk_eigvecs = eigvecs[:, topk_indices]\n",
    "    return topk_eigvals, topk_eigvecs\n",
    "\n",
    "def proj_activ_onto_out_vector(x, out_vector, device='cpu'):\n",
    "    x = x.to(dtype=torch.float64, device=device)\n",
    "    out_vector = out_vector.to(dtype=torch.float64, device=device)\n",
    "    return torch.einsum(\"ohw,o->hw\", x, out_vector)\n",
    "\n",
    "def ablate_eigs(layer_label, state_dict, x, out_vector, idxs, invert=False, device='cpu'):\n",
    "    x = x.to(dtype=torch.float64, device=device)\n",
    "    out_vector = out_vector.to(dtype=torch.float64, device=device)\n",
    "    \n",
    "    B = layer_to_b_tensor(layer_label=layer_label, state_dict=state_dict, device=device)\n",
    "    eigvals, eigvecs = b_tensor_decomp(b_tensor=B, out_vector=out_vector, topk=None, \n",
    "                                     specified_idxs=idxs, device=device)\n",
    "\n",
    "    _, in_chan, k, _ = state_dict[layer_label + \".conv0.weight\"].shape\n",
    "    eigvecs = eigvecs.reshape(in_chan, k, k, eigvecs.shape[-1])\n",
    "\n",
    "    contrib_specific_eigvecs = torch.zeros_like(x[0], dtype=torch.float64, device=device)\n",
    "    \n",
    "    for eig_idx in range(eigvecs.shape[-1]):\n",
    "        eigvec = eigvecs[:,:,:,eig_idx]\n",
    "        padding = (k - 1) // 2\n",
    "        conv = torch.nn.Conv2d(in_channels=in_chan, out_channels=1, kernel_size=k, bias=False, \n",
    "                             padding=padding, stride=1).to(dtype=torch.float64, device=device)\n",
    "        conv.weight = torch.nn.Parameter(eigvec.unsqueeze(0))\n",
    "        conv_output = conv(x).squeeze(0)\n",
    "        contrib = eigvals[eig_idx] * (conv_output**2)\n",
    "        contrib_specific_eigvecs += contrib\n",
    "        \n",
    "    if invert:\n",
    "        return contrib_specific_eigvecs\n",
    "    else:\n",
    "        W = state_dict[layer_label + \".conv0.weight\"]\n",
    "        V = state_dict[layer_label + \".conv1.weight\"]\n",
    "        W_conv = torch.nn.Conv2d(in_channels=W.shape[1], out_channels=W.shape[0], kernel_size=W.shape[2], bias=False, padding=(W.shape[2]-1)//2, stride=1)\n",
    "        V_conv = torch.nn.Conv2d(in_channels=V.shape[1], out_channels=V.shape[0], kernel_size=V.shape[2], bias=False, padding=(V.shape[2]-1)//2, stride=1)\n",
    "        W_conv.weight = torch.nn.Parameter(W)\n",
    "        V_conv.weight = torch.nn.Parameter(V)\n",
    "        total_contrib = W_conv(x) * V_conv(x)\n",
    "        return proj_activ_onto_out_vector(total_contrib,out_vector) - contrib_specific_eigvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.440110832452774e-10\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize random tensors with float64 on specified device\n",
    "W = torch.rand(32, 32, 7, 7, dtype=torch.float64, device=device)\n",
    "V = torch.rand(32, 32, 7, 7, dtype=torch.float64, device=device)\n",
    "x = torch.rand(32, 8, 8, dtype=torch.float64, device=device)  # Adding batch dimension\n",
    "\n",
    "state_dict = {}\n",
    "state_dict[\"conv_seqs.2.res_block0.conv0.weight\"] = W\n",
    "state_dict[\"conv_seqs.2.res_block0.conv1.weight\"] = V\n",
    "\n",
    "# Set up convolutions\n",
    "conv_a = torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=7, bias=False, padding=3, stride=1)\n",
    "conv_b = torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=7, bias=False, padding=3, stride=1)\n",
    "\n",
    "# Move convs to device and float64\n",
    "conv_a = conv_a.to(dtype=torch.float64, device=device)\n",
    "conv_b = conv_b.to(dtype=torch.float64, device=device)\n",
    "\n",
    "# Set weights\n",
    "conv_a.weight = torch.nn.Parameter(W)\n",
    "conv_b.weight = torch.nn.Parameter(V)\n",
    "\n",
    "# Create indices on device\n",
    "indices = torch.arange(0, 32*7*7, device=device)\n",
    "\n",
    "# Initialize out_vector in float64 on device\n",
    "i = torch.randint(0, 32, (1,)).item()\n",
    "out_vector = torch.zeros(32, dtype=torch.float64, device=device)\n",
    "out_vector[i] = 1.0\n",
    "\n",
    "# Calculate contributions\n",
    "channel_contrib_channel0 = ablate_eigs(\n",
    "    layer_label=\"conv_seqs.2.res_block0\",\n",
    "    state_dict=state_dict,\n",
    "    x=x, \n",
    "    out_vector=out_vector, \n",
    "    idxs=indices, \n",
    "    invert=True\n",
    ")\n",
    "\n",
    "# Compute using convolutions\n",
    "output_using_conv_weights = conv_a(x) * conv_b(x)\n",
    "output_using_conv_weights = output_using_conv_weights[i]  # Get first channel of first batch\n",
    "\n",
    "print(torch.max(torch.abs(output_using_conv_weights - channel_contrib_channel0)).item())\n",
    "assert torch.allclose(output_using_conv_weights, channel_contrib_channel0, atol=1e-6, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
